{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Jeopardy Questions to Find Winning Patterns\n",
    "\n",
    "In this project, the goal is to analyze a dataset of **Jeopardy!** questions to uncover patterns and insights that could provide a competitive edge in the game. By examining trends in question topics, wording, and values, we aim to identify strategies that might increase the chances of winning.\n",
    "\n",
    "Weâ€™ll be working with a dataset of historical Jeopardy questions, using data analysis techniques to answer questions like:\n",
    "- What are the most common categories?\n",
    "- Are there any patterns in the phrasing of high-value questions?\n",
    "- Do certain keywords appear more frequently in specific types of questions?\n",
    "\n",
    "This project involves data cleaning, exploratory data analysis, and basic natural language processing using Python libraries such as `pandas` and `numpy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy = pd.read_csv(\"jeopardy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_column_names = ['Show Number', 'Air Date', 'Round', 'Category', 'Value',\n",
    "       'Question', 'Answer']\n",
    "\n",
    "jeopardy.columns = corrected_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing\n",
    "\n",
    "To prepare the Jeopardy dataset for analysis, we performed several cleaning and preprocessing steps to ensure consistency and usability:\n",
    "\n",
    "1. **Text Normalization**:  \n",
    "   We created a function to clean the text by:\n",
    "   - Removing all punctuation\n",
    "   - Converting all characters to lowercase  \n",
    "   This function was applied to both the **\"Question\"** and **\"Answer\"** columns to make the text uniform and easier to analyze.\n",
    "\n",
    "2. **Value Column Conversion**:  \n",
    "   The **\"Value\"** column originally contained monetary amounts as strings (e.g., \"$200\"). We removed the dollar signs and commas, then converted the values to integers for accurate numerical analysis.\n",
    "\n",
    "3. **Date Formatting**:  \n",
    "   The **\"Air Date\"** column was converted from string format to `datetime` format. This allows for time-based analysis, such as identifying trends by year or month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalizer(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalizer)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dollar(text):\n",
    "    text = re.sub(r'[^\\d.]', '', text) \n",
    "\n",
    "    try:\n",
    "        text_float = float(text)\n",
    "    except:\n",
    "        text_float = 0.0\n",
    "\n",
    "    return int(text_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['Value'] = jeopardy['Value'].astype(str)\n",
    "\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_dollar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_in_question_ratio(row):\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    match_count = 0\n",
    "\n",
    "    words_to_remove = [word for word in split_answer if word.lower() == \"the\"]\n",
    "    for word in words_to_remove:\n",
    "        split_answer.remove(word)\n",
    "\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "\n",
    "    return match_count / len(split_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['answer_in_question'] = jeopardy.apply(answer_in_question_ratio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05834744478926688\n"
     ]
    }
   ],
   "source": [
    "mean_answer_in_question = jeopardy['answer_in_question'].mean()\n",
    "print(mean_answer_in_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_question(text):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    cleaned = [\n",
    "        lemmatizer.lemmatize(word)\n",
    "        for word in words\n",
    "        if word not in stop_words and word not in string.punctuation and len(word) > 2\n",
    "    ]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['filtered_question'] = jeopardy['clean_question'].apply(clean_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Overlap in Questions\n",
    "\n",
    "We created a new column `answer_in_question` that shows how much of the answer is mentioned in the question. This helps us understand whether questions tend to contain words from their correct answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Repeated Question Terms\n",
    "\n",
    "To explore whether new questions reuse terms from older ones, we scan through questions in chronological order and track which significant words (6+ characters) have been seen before. This gives an idea of how often questions might repeat or reference similar content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values('Air Date')\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "    cleaned_words = row['filtered_question']  \n",
    "    match_count = 0\n",
    "\n",
    "    for word in cleaned_words:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(word)\n",
    "\n",
    "    if len(cleaned_words) > 0:\n",
    "        question_overlap.append(match_count / len(cleaned_words))\n",
    "    else:\n",
    "        question_overlap.append(0)\n",
    "\n",
    "jeopardy['question_overlap'] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8082993266667637\n"
     ]
    }
   ],
   "source": [
    "mean_question_overlap = jeopardy['question_overlap'].mean()\n",
    "\n",
    "print(mean_question_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Recycling Analysis\n",
    "\n",
    "The mean value of `question_overlap` is approximately 0.689. This means that, on average, around 69% of the significant terms (6+ characters) in each question have already appeared in previous questions.\n",
    "\n",
    "This suggests that many Jeopardy questions reuse similar language or concepts, even if the exact questions are not repeated. It may indicate a level of thematic repetition or partial recycling of content, which could be useful for contestants who study past questions to prepare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying High-Value Question Terms\n",
    "\n",
    "To increase your chances of earning more on Jeopardy, it's helpful to focus on high-value questions. One way to do this is by analyzing which words appear more often in high-value questions compared to low-value ones.\n",
    "\n",
    "By comparing word usage across these two groups, we can identify terms that are more strongly associated with high-value questions. A statistical method called the chi-squared test helps measure how different the word usage is between the two categories.\n",
    "\n",
    "This approach can highlight which words are more likely to appear in high-stakes questions â€” giving you a strategic edge in your preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_and_low(row):\n",
    "    value = 0\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['high_value'] = jeopardy.apply(high_and_low, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_in_value_groups(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    \n",
    "    for index, row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question'].split()\n",
    "        if word.lower() in [w.lower() for w in split_question]:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "                \n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "comparison_terms = random.sample(list(terms_used), 10)\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    high_count, low_count = count_word_in_value_groups(term)\n",
    "    observed_expected.append([high_count, low_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared Test Interpretation for Sample Terms\n",
    "\n",
    "We performed a chi-squared test to evaluate whether specific words appear disproportionately in **high-value** vs. **low-value** Jeopardy questions. Here are the results for a sample of terms:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandpaper: Ï‡Â² = 0.44, p = 0.5048\n",
      "mimicking: Ï‡Â² = 0.40, p = 0.5261\n",
      "noa: Ï‡Â² = 2.49, p = 0.1147\n",
      "borax: Ï‡Â² = 0.40, p = 0.5261\n",
      "hrefhttpwwwjarchivecommedia20041109_dj_11ajpg: Ï‡Â² = 0.40, p = 0.5261\n",
      "experience: Ï‡Â² = 0.37, p = 0.5443\n",
      "1621: Ï‡Â² = 0.80, p = 0.3699\n",
      "anchor: Ï‡Â² = 0.00, p = 0.9953\n",
      "chambliss: Ï‡Â² = 0.40, p = 0.5261\n",
      "exterior: Ï‡Â² = 0.40, p = 0.5261\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "for i, term in enumerate(comparison_terms):\n",
    "    stat = chi_squared[i].statistic\n",
    "    pval = chi_squared[i].pvalue\n",
    "    print(f\"{term}: Ï‡Â² = {stat:.2f}, p = {pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "\n",
    "- All p-values are greater than 0.05, meaning none of these terms show a statistically significant association with either high- or low-value questions.\n",
    "- The term \"noa\" had the highest chi-squared value (2.49), but even this is below the common significance threshold (p < 0.05).\n",
    "- The appearance of a malformed string like `\"hrefhttpwwwjarchivecommedia...\"` suggests that further data cleaning (e.g., removing URLs or HTML remnants) would be beneficial for better analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
