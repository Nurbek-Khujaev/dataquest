{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f1115b-be04-4323-ae86-9029d83c0130",
   "metadata": {},
   "source": [
    "## Message Spam Detection\n",
    "\n",
    "In this  project, we explore the practical application of algorithms by building a spam filter for Message messages. The goal is to develop a model that can automatically classify incoming messages as either \"spam\" or \"ham\" (not spam), using machine learning techniques.\n",
    "\n",
    "We will walk through each step of the process, including data preprocessing, feature extraction, model training, and evaluation, to understand how spam detection works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e339a46-add2-4c18-96be-312248d688e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/Users/nurbekkhujaev/Jupyter/SMSSpamCollection', sep='\\t', header=None, names=['Label', 'Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6c5ae7-c248-4937-8bf6-1cb3f82fad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e52acb-0141-4839-8673-8239c15b9162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5fa5cd-8c4f-4b97-b3e2-9ec17047895b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba923292-82a0-4e55-a07b-38933ce5b56e",
   "metadata": {},
   "source": [
    "### Data Randomization and Splitting\n",
    "\n",
    "We randomized the dataset to eliminate any ordering bias. After shuffling, we split the data into training and test sets using an 80:20 ratio. This ensures that the model has sufficient data to learn from while reserving a portion for unbiased evaluation.\n",
    "\n",
    "We also verified that the class distribution of \"ham\" and \"spam\" messages remains approximately the same in both the training and test sets as in the original dataset. This helps maintain the integrity of the dataset and ensures the model is trained and evaluated on representative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84caaafc-4427-475a-954e-3cf26db87d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_randomized = data.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9256d35b-7471-4f0d-bf32-68c344331078",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(0.8 * len(data_randomized))\n",
    "\n",
    "train_df = data_randomized[:split_point].reset_index(drop=True)\n",
    "test_df = data_randomized[split_point:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6f52a5-91d4-40d6-8224-49ab7c2a2360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.86538\n",
       "spam    0.13462\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b7203b7-be02-433b-857e-1490f03ed72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.868161\n",
       "spam    0.131839\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f9d994b-06b3-4c75-9095-7a505330ce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 2)\n",
      "(1115, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060d4ef-d035-4377-9691-1aa997e166e9",
   "metadata": {},
   "source": [
    "### Letter Case and Punctuation\n",
    "\n",
    "As part of preprocessing, we cleaned the text data by removing punctuation and converting all characters to lowercase. This step helps standardize the messages and reduces noise in the data, making it easier for the model to identify meaningful patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0850ac65-70ee-4a8a-bd9a-158a2bfc8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Message'] = train_df['Message'].str.replace(r'\\W', ' ')\n",
    "train_df['Message'] = train_df['Message'].str.lower()\n",
    "\n",
    "test_df['Message'] = test_df['Message'].str.replace(r'\\W', ' ')\n",
    "test_df['Message'] = test_df['Message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce2a814-f669-482c-8291-89f7cddf9143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>wherre's my boytoy ? :-(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>later i guess. i needa do mcat study too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>but i haf enuff space got like 4 mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 10 mths? update to latest oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>all sounds good. fingers . makes it difficult ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham                           wherre's my boytoy ? :-(\n",
       "1   ham          later i guess. i needa do mcat study too.\n",
       "2   ham             but i haf enuff space got like 4 mb...\n",
       "3  spam  had your mobile 10 mths? update to latest oran...\n",
       "4   ham  all sounds good. fingers . makes it difficult ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e6e9ec-27bd-4977-8e20-9db1689e3351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes, princess. are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth.. there's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham                       yep, by the pretty sculpture\n",
       "1   ham      yes, princess. are you going to make me moan?\n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent.\n",
       "4   ham  i forgot 2 ask ü all smth.. there's a card on ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a923aba-85d4-43a5-a5a5-253b3c884547",
   "metadata": {},
   "source": [
    "### Text Vectorization\n",
    "\n",
    "After cleaning the text data, we transformed the Message messages into numerical format using a technique called Bag of Words (BoW). In this approach, we create a vocabulary of all unique words across the dataset and represent each message as a vector indicating the frequency of each word.\n",
    "\n",
    "For example, the message:\n",
    "\n",
    "\"SECRET PRIZE! CLAIM SECRET PRIZE NOW!!\"\n",
    "\n",
    "is transformed into a vector that counts how many times each word appears (e.g., \"secret\": 2, \"prize\": 2, \"claim\": 1, etc.). This step converts raw text into a format that can be used by machine learning models, allowing them to identify patterns in the word usage between spam and ham messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdd22f-7278-4d3f-b3eb-2ef4250f7207",
   "metadata": {},
   "source": [
    "### Building the Vocabulary\n",
    "\n",
    "To prepare for vectorization, we first created a list of all unique words that appear in the messages of the training set. This list forms the vocabulary for our Bag of Words model.\n",
    "\n",
    "By scanning through each message in the training data, we collected every distinct word after cleaning, ensuring that each word appears only once in the vocabulary. This vocabulary will later be used to construct the word frequency vectors for each message, enabling the model to interpret and learn from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b7ed23-09a1-40c7-831d-f6d0c1d5df7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         yep, by the pretty sculpture\n",
       "1        yes, princess. are you going to make me moan?\n",
       "2                           welp apparently he retired\n",
       "3                                              havent.\n",
       "4    i forgot 2 ask ü all smth.. there's a card on ...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Message'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11c35d08-4890-487c-87fd-574081790b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Message'] = train_df['Message'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for col in train_df['Message']:\n",
    "    for word in col:\n",
    "        vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2663f173-48e3-4c9a-85e4-d6235d38ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b99695-002a-4b1f-86a8-ce6024268a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_message = {unique_word: [0] * len(train_df['Message']) for unique_word in vocabulary}\n",
    "\n",
    "for index, message in enumerate(train_df['Message']):\n",
    "    for word in message:\n",
    "        word_counts_per_message[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77e44e3f-4b11-4080-991b-37b21a2682ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06dbfecf-35fe-40f0-9c93-06d2711c4684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chef</th>\n",
       "      <th>satthen</th>\n",
       "      <th>idk</th>\n",
       "      <th>sayhey!</th>\n",
       "      <th>headin</th>\n",
       "      <th>other.</th>\n",
       "      <th>paris</th>\n",
       "      <th>thought-</th>\n",
       "      <th>home!</th>\n",
       "      <th>nap..</th>\n",
       "      <th>...</th>\n",
       "      <th>os</th>\n",
       "      <th>millers</th>\n",
       "      <th>yes.he</th>\n",
       "      <th>empty</th>\n",
       "      <th>heater</th>\n",
       "      <th>strange.</th>\n",
       "      <th>appreciated</th>\n",
       "      <th>subscriptions.</th>\n",
       "      <th>nyc,</th>\n",
       "      <th>standing...|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11859 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chef  satthen  idk  sayhey!  headin  other.  paris  thought-  home!  nap..  \\\n",
       "0     0        0    0        0       0       0      0         0      0      0   \n",
       "1     0        0    0        0       0       0      0         0      0      0   \n",
       "2     0        0    0        0       0       0      0         0      0      0   \n",
       "3     0        0    0        0       0       0      0         0      0      0   \n",
       "4     0        0    0        0       0       0      0         0      0      0   \n",
       "\n",
       "   ...  os  millers  yes.he  empty  heater  strange.  appreciated  \\\n",
       "0  ...   0        0       0      0       0         0            0   \n",
       "1  ...   0        0       0      0       0         0            0   \n",
       "2  ...   0        0       0      0       0         0            0   \n",
       "3  ...   0        0       0      0       0         0            0   \n",
       "4  ...   0        0       0      0       0         0            0   \n",
       "\n",
       "   subscriptions.  nyc,  standing...|  \n",
       "0               0     0             0  \n",
       "1               0     0             0  \n",
       "2               0     0             0  \n",
       "3               0     0             0  \n",
       "4               0     0             0  \n",
       "\n",
       "[5 rows x 11859 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d263c67d-cd71-4b52-a405-6a1c255d65a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>chef</th>\n",
       "      <th>satthen</th>\n",
       "      <th>idk</th>\n",
       "      <th>sayhey!</th>\n",
       "      <th>headin</th>\n",
       "      <th>other.</th>\n",
       "      <th>paris</th>\n",
       "      <th>thought-</th>\n",
       "      <th>...</th>\n",
       "      <th>os</th>\n",
       "      <th>millers</th>\n",
       "      <th>yes.he</th>\n",
       "      <th>empty</th>\n",
       "      <th>heater</th>\n",
       "      <th>strange.</th>\n",
       "      <th>appreciated</th>\n",
       "      <th>subscriptions.</th>\n",
       "      <th>nyc,</th>\n",
       "      <th>standing...|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep,, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes,, princess., are, you, going, to, make, m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent.]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth.., there's, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  chef  satthen  \\\n",
       "0   ham                 [yep,, by, the, pretty, sculpture]     0        0   \n",
       "1   ham  [yes,, princess., are, you, going, to, make, m...     0        0   \n",
       "2   ham                    [welp, apparently, he, retired]     0        0   \n",
       "3   ham                                          [havent.]     0        0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth.., there's, a...     0        0   \n",
       "\n",
       "   idk  sayhey!  headin  other.  paris  thought-  ...  os  millers  yes.he  \\\n",
       "0    0        0       0       0      0         0  ...   0        0       0   \n",
       "1    0        0       0       0      0         0  ...   0        0       0   \n",
       "2    0        0       0       0      0         0  ...   0        0       0   \n",
       "3    0        0       0       0      0         0  ...   0        0       0   \n",
       "4    0        0       0       0      0         0  ...   0        0       0   \n",
       "\n",
       "   empty  heater  strange.  appreciated  subscriptions.  nyc,  standing...|  \n",
       "0      0       0         0            0               0     0             0  \n",
       "1      0       0         0            0               0     0             0  \n",
       "2      0       0         0            0               0     0             0  \n",
       "3      0       0         0            0               0     0             0  \n",
       "4      0       0         0            0               0     0             0  \n",
       "\n",
       "[5 rows x 11861 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean = pd.concat([train_df, word_counts], axis=1)\n",
    "train_df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808e24c-3180-4464-b7e8-87ea9b4d76b0",
   "metadata": {},
   "source": [
    "### Building the Spam Filter with Naive Bayes\n",
    "\n",
    "With the data cleaned and the training set prepared, we can now begin constructing our spam filter. We’ll use the Naive Bayes algorithm, a popular and effective method for text classification tasks like spam detection.\n",
    "\n",
    "We will use the training data to calculate the probabilities needed for the algorithm to classify new, unseen messages as either spam or ham."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd26e78-f254-4bcb-a5e5-165649de5436",
   "metadata": {},
   "source": [
    "### Calculating Constants for Naive Bayes\n",
    "\n",
    "Before we can apply the Naive Bayes algorithm, we need to calculate a few constants that will be used repeatedly when classifying new messages:\n",
    "\n",
    "- **p_spam**: The probability that any given message is spam.\n",
    "- **p_ham**: The probability that any given message is ham (not spam).\n",
    "- **n_spam**: The total number of words in all spam messages.\n",
    "- **n_ham**: The total number of words in all ham messages.\n",
    "- **n_vocabulary**: The total number of unique words in the training set vocabulary.\n",
    "\n",
    "We also apply Laplace smoothing to handle zero probabilities for words that may not appear in some classes. For this, we set the smoothing parameter **alpha** = 1.\n",
    "\n",
    "These constants are essential for calculating the conditional probabilities of words given a class, which will then be used to compute the overall probability of a message being spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e6be378-9bcb-4788-afc0-140f39722e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages = train_df_clean[train_df_clean['Label'] == 'spam']\n",
    "ham_messages = train_df_clean[train_df_clean['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bef54b97-4925-454f-86e7-4b7ca067b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = len(spam_messages) / len(train_df)\n",
    "p_ham = len(ham_messages) / len(train_df)\n",
    "\n",
    "n_words_per_spam_message = spam_messages['Message'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "n_words_per_ham_message = ham_messages['Message'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47659fe-b2da-4901-8f20-b062b5e01037",
   "metadata": {},
   "source": [
    "### Calculating Parameters\n",
    "\n",
    "Next, we calculate the conditional probabilities of each word given a class — that is, how likely a word is to appear in spam versus ham messages. These probabilities form the core of the Naive Bayes model.\n",
    "\n",
    "For each word w in the vocabulary, we compute:\n",
    "\n",
    "- P(w | Spam) = (Number of occurrences of w in spam messages + alpha) / (n_spam + alpha × n_vocabulary)\n",
    "- P(w | Ham) = (Number of occurrences of w in ham messages + alpha) / (n_ham + alpha × n_vocabulary)\n",
    "\n",
    "This step ensures that every word, even those not seen in one of the classes, has a non-zero probability thanks to smoothing. These word probabilities will be used later when classifying new messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e0d2f54-d4b9-4d71-981d-11f6a07899b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()  \n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()   \n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9241b579-6210-4512-a4f5-3ebf93b7044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    \n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ae882a4-bbfa-49d4-9339-42832924bc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.168667088083531e-26\n",
      "P(Ham|message): 6.093223663290184e-28\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b9e1276-2516-40b1-b213-d1950971b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.8003668602200727e-18\n",
      "P(Ham|message): 7.788307098631482e-15\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"hello are you coming today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612546b-54c0-499e-ac59-63431be2757c",
   "metadata": {},
   "source": [
    "### Evaluating the Spam Filter on the Test Set\n",
    "\n",
    "With our Naive Bayes spam filter fully trained, we now evaluate its performance using the test set. For each message in the test set, we:\n",
    "\n",
    "1. Calculate the probability that the message is spam.\n",
    "2. Calculate the probability that the message is ham.\n",
    "3. Compare the two and classify the message based on the higher probability.\n",
    "\n",
    "Once all messages are classified, we compare the predicted labels with the actual labels to measure the model’s accuracy.\n",
    "\n",
    "Accuracy is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "$$\n",
    "\n",
    "This metric gives us a clear indication of how well the spam filter generalizes to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fa53ff5-557a-4bf1-8f6f-925b804e16b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac60e60f-4047-4384-9887-3f487386bec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>wherre's my boytoy ? :-(</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>later i guess. i needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>but i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 10 mths? update to latest oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>all sounds good. fingers . makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message Predicted\n",
       "0   ham                           wherre's my boytoy ? :-(       ham\n",
       "1   ham          later i guess. i needa do mcat study too.       ham\n",
       "2   ham             but i haf enuff space got like 4 mb...       ham\n",
       "3  spam  had your mobile 10 mths? update to latest oran...      spam\n",
       "4   ham  all sounds good. fingers . makes it difficult ...       ham"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Predicted'] = test_df['Message'].apply(classify_test_set)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdd5fc34-2119-4646-83d5-d69680a721a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1091\n",
      "Incorrect: 24\n",
      "Accuracy: 0.97847533632287\n"
     ]
    }
   ],
   "source": [
    "correct = (test_df['Label'] == test_df['Predicted']).sum()\n",
    "total = len(test_df)\n",
    "\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3033ff0-b441-487c-a30e-bb812e1339cd",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The spam filter achieved an accuracy of 97.85% on the test set:\n",
    "\n",
    "This high accuracy indicates that the Naive Bayes model is performing well in distinguishing between spam and ham messages in real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f031284-ed88-47f7-b7a4-8d2ad19584fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = test_df[test_df['Label'] != test_df['Predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c71dab9-a01c-4c95-8b3d-c02ad06389ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>spam</td>\n",
       "      <td>not heard from u4 a while. call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>spam</td>\n",
       "      <td>more people are dogging in your area now. call...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>ham</td>\n",
       "      <td>unlimited texts. limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th of july</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>ham</td>\n",
       "      <td>nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>ham</td>\n",
       "      <td>a boy loved a gal. he propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>ham</td>\n",
       "      <td>we have sent jd for customer service cum accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>spam</td>\n",
       "      <td>email alertfrom: jeri stewartsize: 2kbsubject:...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>ham</td>\n",
       "      <td>hasn't that been the pattern recently crap wee...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>ham</td>\n",
       "      <td>madam,regret disturbance.might receive a refer...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>spam</td>\n",
       "      <td>ur balance is now £600. next question: complet...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>spam</td>\n",
       "      <td>oh my god! i've found your number again! i'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>spam</td>\n",
       "      <td>sorry! u can not unsubscribe yet. the mob offe...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>spam</td>\n",
       "      <td>hi babe its chloe, how r u? i was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>spam</td>\n",
       "      <td>am new 2 club &amp; dont fink we met yet will b gr...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>spam</td>\n",
       "      <td>0a$networks allow companies to bill for sms, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>ham</td>\n",
       "      <td>these won't do. have to move on to morphine</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>spam</td>\n",
       "      <td>rct' thnq adrian for u text. rgds vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>spam</td>\n",
       "      <td>dont forget you can place as many free request...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>spam</td>\n",
       "      <td>hello. we need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>spam</td>\n",
       "      <td>ringtoneking 84484</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>spam</td>\n",
       "      <td>a link to your picture has been sent. you can ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>ham</td>\n",
       "      <td>i (career tel) have added u as a contact on in...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                            Message  \\\n",
       "115   spam  not heard from u4 a while. call me now am here...   \n",
       "136   spam  more people are dogging in your area now. call...   \n",
       "153    ham                  unlimited texts. limited minutes.   \n",
       "160    ham                                       26th of july   \n",
       "285    ham                             nokia phone is lovly..   \n",
       "294    ham  a boy loved a gal. he propsd bt she didnt mind...   \n",
       "320    ham  we have sent jd for customer service cum accou...   \n",
       "364   spam  email alertfrom: jeri stewartsize: 2kbsubject:...   \n",
       "399    ham  hasn't that been the pattern recently crap wee...   \n",
       "493    ham  madam,regret disturbance.might receive a refer...   \n",
       "501   spam  ur balance is now £600. next question: complet...   \n",
       "505   spam  oh my god! i've found your number again! i'm s...   \n",
       "513   spam  sorry! u can not unsubscribe yet. the mob offe...   \n",
       "547   spam  hi babe its chloe, how r u? i was smashed on s...   \n",
       "650   spam  am new 2 club & dont fink we met yet will b gr...   \n",
       "742   spam  0a$networks allow companies to bill for sms, s...   \n",
       "825    ham        these won't do. have to move on to morphine   \n",
       "877   spam           rct' thnq adrian for u text. rgds vatian   \n",
       "886   spam                                      2/2 146tf150p   \n",
       "918   spam  dont forget you can place as many free request...   \n",
       "954   spam  hello. we need some posh birds and chaps to us...   \n",
       "978   spam                                 ringtoneking 84484   \n",
       "1007  spam  a link to your picture has been sent. you can ...   \n",
       "1074   ham  i (career tel) have added u as a contact on in...   \n",
       "\n",
       "                       Predicted  \n",
       "115                          ham  \n",
       "136                          ham  \n",
       "153                         spam  \n",
       "160                         spam  \n",
       "285                         spam  \n",
       "294   needs human classification  \n",
       "320                         spam  \n",
       "364                          ham  \n",
       "399                         spam  \n",
       "493                         spam  \n",
       "501                          ham  \n",
       "505                          ham  \n",
       "513                          ham  \n",
       "547                          ham  \n",
       "650                          ham  \n",
       "742                          ham  \n",
       "825                         spam  \n",
       "877                          ham  \n",
       "886                          ham  \n",
       "918                          ham  \n",
       "954                          ham  \n",
       "978                          ham  \n",
       "1007                         ham  \n",
       "1074                        spam  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9844bd73-da99-45d8-9ca9-90baa283f2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not heard from u4 a while. call me now am here all night with just my knickers on. make me beg for it like u did last time 01223585236 xx luv nikiyu4.net\n",
      "P(Spam|message): 2.535810010954546e-99\n",
      "P(Ham|message): 2.8500294939879786e-87\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "more people are dogging in your area now. call 09090204448 and join like minded guys. why not arrange 1 yourself. there's 1 this evening. a£1.50 minapn ls278bb\n",
      "P(Spam|message): 8.869058556592091e-86\n",
      "P(Ham|message): 6.065005527292867e-83\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "unlimited texts. limited minutes.\n",
      "P(Spam|message): 6.046145907395024e-12\n",
      "P(Ham|message): 8.116382971423812e-13\n",
      "Label: Spam\n",
      "None\n",
      " \n",
      "26th of july\n",
      "P(Spam|message): 2.3882276334210343e-12\n",
      "P(Ham|message): 1.176163567437907e-12\n",
      "Label: Spam\n",
      "None\n",
      " \n",
      "nokia phone is lovly..\n",
      "P(Spam|message): 1.5083924809769105e-09\n",
      "P(Ham|message): 2.2566962084967214e-10\n",
      "Label: Spam\n",
      "None\n",
      " \n",
      "a boy loved a gal. he propsd bt she didnt mind. he gv lv lttrs, bt her frnds threw thm. again d boy decided 2 aproach d gal , dt time a truck was speeding towards d gal. wn it was about 2 hit d girl,d boy ran like hell n saved her. she asked 'hw cn u run so fast?' d boy replied \"boost is d secret of my energy\" n instantly d girl shouted \"our energy\" n thy lived happily 2gthr drinking boost evrydy moral of d story:- i hv free msgs:d;): gud ni8\n",
      "P(Spam|message): 0.0\n",
      "P(Ham|message): 0.0\n",
      "Equal proabilities, have a human classify this!\n",
      "None\n",
      " \n",
      "we have sent jd for customer service cum accounts executive to ur mail id, for details contact us\n",
      "P(Spam|message): 3.805117197695665e-60\n",
      "P(Ham|message): 1.5191427017667635e-61\n",
      "Label: Spam\n",
      "None\n",
      " \n",
      "email alertfrom: jeri stewartsize: 2kbsubject: low-cost prescripiton drvgsto listen to email call 123\n",
      "P(Spam|message): 9.335747202955583e-26\n",
      "P(Ham|message): 1.0284265189726734e-25\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "hasn't that been the pattern recently crap weekends?\n",
      "P(Spam|message): 1.2763333433921026e-29\n",
      "P(Ham|message): 5.052876118349821e-30\n",
      "Label: Spam\n",
      "None\n",
      " \n",
      "madam,regret disturbance.might receive a reference check from dlf premarica.kindly be informed.rgds,rakhesh,kerala.\n",
      "P(Spam|message): 1.095475437495239e-49\n",
      "P(Ham|message): 3.308861076813488e-50\n",
      "Label: Spam\n",
      "None\n",
      " \n",
      "ur balance is now £600. next question: complete the landmark, big, a. bob, b. barry or c. ben ?. text a, b or c to 83738. good luck!\n",
      "P(Spam|message): 2.881116519850354e-73\n",
      "P(Ham|message): 2.4836845947093162e-71\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "oh my god! i've found your number again! i'm so glad, text me back xafter this msgs cst std ntwk chg £1.50\n",
      "P(Spam|message): 3.38348006576591e-79\n",
      "P(Ham|message): 1.2710629562192737e-72\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "sorry! u can not unsubscribe yet. the mob offer package has a min term of 54 weeks> pls resubmit request after expiry. reply themob help 4 more info\n",
      "P(Spam|message): 5.362700020067889e-81\n",
      "P(Ham|message): 1.0594179805858227e-80\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "hi babe its chloe, how r u? i was smashed on saturday night, it was great! how was your weekend? u been missing me? sp visionsms.com text stop to stop 150p/text\n",
      "P(Spam|message): 2.418025526242907e-103\n",
      "P(Ham|message): 6.711851641402087e-94\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "am new 2 club & dont fink we met yet will b gr8 2 c u please leave msg 2day wiv ur area 09099726553 reply promised carlie x calls£1/minmobsmore lkpobox177hp51fl\n",
      "P(Spam|message): 2.7830057594930036e-83\n",
      "P(Ham|message): 1.3666207331095415e-82\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "0a$networks allow companies to bill for sms, so they are responsible for their \"suppliers\", just as a shop has to give a guarantee on what they sell. b. g.\n",
      "P(Spam|message): 4.887923655886029e-75\n",
      "P(Ham|message): 5.963895754153255e-70\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "these won't do. have to move on to morphine\n",
      "P(Spam|message): 4.4631293977168994e-27\n",
      "P(Ham|message): 3.3091570531047796e-28\n",
      "Label: Spam\n",
      "None\n",
      " \n",
      "rct' thnq adrian for u text. rgds vatian\n",
      "P(Spam|message): 8.676642607325378e-09\n",
      "P(Ham|message): 4.199818951138842e-08\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "2/2 146tf150p\n",
      "P(Spam|message): 3.704558273734364e-06\n",
      "P(Ham|message): 1.0128297613063414e-05\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "dont forget you can place as many free requests with 1stchoice.co.uk as you wish. for more information call 08707808226.\n",
      "P(Spam|message): 2.3986015213782214e-62\n",
      "P(Ham|message): 7.96633461640728e-61\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "hello. we need some posh birds and chaps to user trial prods for champneys. can i put you down? i need your address and dob asap. ta r\n",
      "P(Spam|message): 5.505939986806575e-74\n",
      "P(Ham|message): 1.4878292072779482e-63\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "ringtoneking 84484\n",
      "P(Spam|message): 0.13461969934933812\n",
      "P(Ham|message): 0.8653803006506618\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "a link to your picture has been sent. you can also use http://alto18.co.uk/wave/wave.asp?o=44345\n",
      "P(Spam|message): 6.103892396264093e-50\n",
      "P(Ham|message): 8.522544450508086e-49\n",
      "Label: Ham\n",
      "None\n",
      " \n",
      "i (career tel) have added u as a contact on indyarocks.com to send free sms. to remove from phonebook - sms no to  &lt;#&gt;\n",
      "P(Spam|message): 5.214439305320257e-66\n",
      "P(Ham|message): 1.015409011500113e-66\n",
      "Label: Spam\n",
      "None\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for message in incorrect['Message']:\n",
    "    print(message)\n",
    "    print(classify(message))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141dd900-083c-4540-b0a5-8c91d633a6fe",
   "metadata": {},
   "source": [
    "### Model Evaluation and Misclassification Analysis\n",
    "\n",
    "Despite using Laplace smoothing (α = 1), several spam messages were still misclassified as \"Ham\", including those with:\n",
    "- Adult content\n",
    "- Premium-rate numbers\n",
    "- Promotional phrases\n",
    "\n",
    "#### Key Observations:\n",
    "- P(Spam|message) was significantly lower than P(Ham|message) for many clearly spammy texts.\n",
    "- This suggests the classifier's word probabilities for spam are undertrained, even with smoothing.\n",
    "\n",
    "#### Likely Causes:\n",
    "- Training data limitations: The model may not have seen enough spam examples with relevant vocabulary.\n",
    "- Weak feature representation:\n",
    "  - Words common in spam may also appear in ham messages, making them less discriminative.\n",
    "  - Lack of bigram/trigram features means context is lost (e.g., \"free\" vs. \"free tonight\").\n",
    "- Imbalanced dataset: If ham messages dominate, the model may be skewed toward predicting ham.\n",
    "- Preprocessing limitations:\n",
    "  - Phone numbers and URLs are treated as generic words.\n",
    "  - No normalization of word forms (stemming/lemmatization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2049c2-e137-4a37-8733-e1871658d2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
